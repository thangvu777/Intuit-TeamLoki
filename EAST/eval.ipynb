{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.17.2)\n",
      "Requirement already satisfied: tensorflow==1.15 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.11.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.33.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.28.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n",
      "Requirement already satisfied: h5py in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.9.0)\n",
      "Requirement already satisfied: pytesseract in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (0.3.3)\n",
      "Requirement already satisfied: Pillow in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (from pytesseract) (6.2.0)\n",
      "Requirement already satisfied: shapely in /Users/Taaha/opt/anaconda3/lib/python3.7/site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install tensorflow==1.15\n",
    "!{sys.executable} -m pip install pytesseract\n",
    "!{sys.executable} -m pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pytesseract\n",
    "from pandas import ExcelFile\n",
    "\n",
    "import locality_aware_nms as nms_locality\n",
    "import lanms\n",
    "\n",
    "tf.app.flags.DEFINE_string('test_data_path', 'images/', '')\n",
    "tf.app.flags.DEFINE_string('gpu_list', '0', '')\n",
    "tf.app.flags.DEFINE_string('checkpoint_path', 'east_icdar2015_resnet_v1_50_rbox/', '')\n",
    "tf.app.flags.DEFINE_string('output_dir', 'tmp/', '')\n",
    "tf.app.flags.DEFINE_string('truth_path', 'W2_Truth_and_Noise_DataSet.xlsx', '')\n",
    "tf.app.flags.DEFINE_bool('no_write_images', False, 'do not write images')\n",
    "\n",
    "import model\n",
    "from icdar import restore_rectangle\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unchanged\n",
    "def get_images():\n",
    "    '''\n",
    "    find image files in test data path\n",
    "    :return: list of files found\n",
    "    '''\n",
    "    files = []\n",
    "    exts = ['jpg', 'png', 'jpeg', 'JPG']\n",
    "    for parent, dirnames, filenames in os.walk(FLAGS.test_data_path):\n",
    "        for filename in filenames:\n",
    "            for ext in exts:\n",
    "                if filename.endswith(ext):\n",
    "                    files.append(os.path.join(parent, filename))\n",
    "                    break\n",
    "    print('Find {} images'.format(len(files)))\n",
    "    return files\n",
    "\n",
    "#unchanged\n",
    "def resize_image(im, max_side_len=2400):\n",
    "    '''\n",
    "    resize image to a size multiple of 32 which is required by the network\n",
    "    :param im: the resized image\n",
    "    :param max_side_len: limit of max image size to avoid out of memory in gpu\n",
    "    :return: the resized image and the resize ratio\n",
    "    '''\n",
    "    h, w, _ = im.shape\n",
    "\n",
    "    resize_w = w\n",
    "    resize_h = h\n",
    "\n",
    "    # limit the max side\n",
    "    if max(resize_h, resize_w) > max_side_len:\n",
    "        ratio = float(max_side_len) / resize_h if resize_h > resize_w else float(max_side_len) / resize_w\n",
    "    else:\n",
    "        ratio = 1.\n",
    "    resize_h = int(resize_h * ratio)\n",
    "    resize_w = int(resize_w * ratio)\n",
    "\n",
    "    resize_h = resize_h if resize_h % 32 == 0 else (resize_h // 32 - 1) * 32\n",
    "    resize_w = resize_w if resize_w % 32 == 0 else (resize_w // 32 - 1) * 32\n",
    "    resize_h = max(32, resize_h)\n",
    "    resize_w = max(32, resize_w)\n",
    "    im = cv2.resize(im, (int(resize_w), int(resize_h)))\n",
    "\n",
    "    ratio_h = resize_h / float(h)\n",
    "    ratio_w = resize_w / float(w)\n",
    "\n",
    "    return im, (ratio_h, ratio_w)\n",
    "#unchanged\n",
    "def detect(score_map, geo_map, timer, score_map_thresh=0.8, box_thresh=0.1, nms_thres=0.2):\n",
    "    '''\n",
    "    restore text boxes from score map and geo map\n",
    "    :param score_map:\n",
    "    :param geo_map:\n",
    "    :param timer:\n",
    "    :param score_map_thresh: threshhold for score map\n",
    "    :param box_thresh: threshhold for boxes\n",
    "    :param nms_thres: threshold for nms\n",
    "    :return:\n",
    "    '''\n",
    "    if len(score_map.shape) == 4:\n",
    "        score_map = score_map[0, :, :, 0]\n",
    "        geo_map = geo_map[0, :, :, ]\n",
    "    # filter the score map\n",
    "    xy_text = np.argwhere(score_map > score_map_thresh)\n",
    "    # sort the text boxes via the y axis\n",
    "    xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
    "    # restore\n",
    "    start = time.time()\n",
    "    text_box_restored = restore_rectangle(xy_text[:, ::-1]*4, geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
    "    print('{} text boxes before nms'.format(text_box_restored.shape[0]))\n",
    "    boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
    "    boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
    "    boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
    "    timer['restore'] = time.time() - start\n",
    "    # nms part\n",
    "    start = time.time()\n",
    "    # boxes = nms_locality.nms_locality(boxes.astype(np.float64), nms_thres)\n",
    "    boxes = lanms.merge_quadrangle_n9(boxes.astype('float32'), nms_thres)\n",
    "    timer['nms'] = time.time() - start\n",
    "\n",
    "    if boxes.shape[0] == 0:\n",
    "        return None, timer\n",
    "\n",
    "    # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
    "    for i, box in enumerate(boxes):\n",
    "        mask = np.zeros_like(score_map, dtype=np.uint8)\n",
    "        cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32) // 4, 1)\n",
    "        boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
    "    boxes = boxes[boxes[:, 8] > box_thresh]\n",
    "\n",
    "    return boxes, timer\n",
    "#unchanged\n",
    "def sort_poly(p):\n",
    "    min_axis = np.argmin(np.sum(p, axis=1))\n",
    "    p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
    "    if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
    "        return p\n",
    "    else:\n",
    "        return p[[0, 3, 2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert excel into readable pandas format and then convert to python dict\n",
    "\n",
    "def get_excel_docs(excel_path:str, sheet:int):\n",
    "    xls = ExcelFile(excel_path)\n",
    "\n",
    "    # have two dataframes, one that is used to get the correct file names and one for the truth\n",
    "    file_names_df = xls.parse(xls.sheet_names[sheet])\n",
    "    truth_df = xls.parse(xls.sheet_names[0])\n",
    "\n",
    "    file_name_docs = file_names_df.to_dict('records')\n",
    "    truth_docs = truth_df.to_dict('records')\n",
    "\n",
    "    # get the file names from the specified sheet\n",
    "    truth_file_name_list = []\n",
    "    if sheet == 0:\n",
    "        for doc in file_name_docs:\n",
    "            truth_file_name_list.append(doc['File_BaseName'])\n",
    "    elif sheet == 1:\n",
    "        for doc in file_name_docs:\n",
    "            truth_file_name_list.append(doc['file_name'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sheet number\")\n",
    "    return truth_file_name_list, truth_docs\n",
    "\n",
    "def typeFloat(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get boxes\n",
    "def getBox(box,im):\n",
    "    h = max(box[2,1],box[3,1]) - min(box[0,1],box[1,1])\n",
    "    w = max(box[1,0],box[2,0]) - min(box[0,0],box[3,0])\n",
    "    x = min(box[0,0],box[3,0])\n",
    "    y = min(box[0,1],box[1,1])\n",
    "    crop_img = im[y:y + h, x:x + w]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu_list\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.makedirs(FLAGS.output_dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != 17:\n",
    "            raise\n",
    "\n",
    "    with tf.get_default_graph().as_default():\n",
    "        input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_images')\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        f_score, f_geometry = model.model(input_images, is_training=False)\n",
    "\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)\n",
    "        saver = tf.train.Saver(variable_averages.variables_to_restore())\n",
    "\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            ckpt_state = tf.train.get_checkpoint_state(FLAGS.checkpoint_path)\n",
    "            model_path = os.path.join(FLAGS.checkpoint_path, os.path.basename(ckpt_state.model_checkpoint_path))\n",
    "            print('Restore from {}'.format(model_path))\n",
    "            saver.restore(sess, model_path)\n",
    "            parse = []\n",
    "            im_fn_list = get_images()\n",
    "            dir = '/Users/Taaha/Documents/projects/EAST'\n",
    "            excel_path = os.path.join(dir, FLAGS.truth_path)\n",
    "            truth_file_name_list, truth_docs = get_excel_docs(excel_path, 0)\n",
    "            \n",
    "\n",
    "            # Open text file with headers\n",
    "            with open (\"headers.txt\", \"r\") as myFile : \n",
    "                headers = myFile.read().split()\n",
    "\n",
    "            for index, im_fn in enumerate(im_fn_list):\n",
    "                # save accuracy and time to compute averages\n",
    "                accuracy_list = []\n",
    "                time_list = []\n",
    "                float_accuracy_list = []\n",
    "                string_accuracy_list = []\n",
    "                fuzzy_score_list = []\n",
    "\n",
    "                floatCorrect = 0\n",
    "                floatWrong = 0\n",
    "                stringCorrect = 0\n",
    "                stringWrong = 0\n",
    "                num_correct = 0\n",
    "                num_total = 0\n",
    "                allWords = []\n",
    "                \n",
    "                im = cv2.imread(im_fn)[:, :, ::-1]\n",
    "                start_time = time.time()\n",
    "                im_resized, (ratio_h, ratio_w) = resize_image(im)\n",
    "\n",
    "                timer = {'net': 0, 'restore': 0, 'nms': 0}\n",
    "                start = time.time()\n",
    "                score, geometry = sess.run([f_score, f_geometry], feed_dict={input_images: [im_resized]})\n",
    "                timer['net'] = time.time() - start\n",
    "\n",
    "                boxes, timer = detect(score_map=score, geo_map=geometry, timer=timer)\n",
    "                print('{} : net {:.0f}ms, restore {:.0f}ms, nms {:.0f}ms'.format(\n",
    "                    im_fn, timer['net']*1000, timer['restore']*1000, timer['nms']*1000))\n",
    "\n",
    "                if boxes is not None:\n",
    "                    boxes = boxes[:, :8].reshape((-1, 4, 2))\n",
    "                    boxes[:, :, 0] /= ratio_w\n",
    "                    boxes[:, :, 1] /= ratio_h\n",
    "\n",
    "                duration = time.time() - start_time\n",
    "                print('[timing] {}'.format(duration))\n",
    "\n",
    "                #truth\n",
    "                truth_doc = truth_docs[index]\n",
    "                field_names = truth_doc.values()\n",
    "                start_time = time.time()\n",
    "\n",
    "                # save to file\n",
    "                if boxes is not None:\n",
    "                    res_file = os.path.join(\n",
    "                        FLAGS.output_dir,\n",
    "                        '{}.txt'.format(\n",
    "                            os.path.basename(im_fn).split('.')[0]))\n",
    "                    with open(res_file, 'w') as f:\n",
    "                        for box in boxes:\n",
    "                            # to avoid submitting errors\n",
    "                            box = sort_poly(box.astype(np.int32))\n",
    "                            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3]-box[0]) < 5:\n",
    "                                continue\n",
    "                            f.write('{},{},{},{},{},{},{},{}\\r\\n'.format(\n",
    "                                box[0, 0], box[0, 1], box[1, 0], box[1, 1], box[2, 0], box[2, 1], box[3, 0], box[3, 1],\n",
    "                            ))\n",
    "                            \n",
    "                            crop_img = getBox(box,im)\n",
    "                            output = pytesseract.image_to_string(crop_img)\n",
    "                            allWords.append(output)\n",
    "\n",
    "                            #cv2.imshow(\"box\",crop_img)\n",
    "                            #cv2.waitKey(0)\n",
    "                            cv2.polylines(im[:, :, ::-1], [box.astype(np.int32).reshape((-1, 1, 2))], True, color=(255, 255, 0), thickness=1)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                allWords.remove('')\n",
    "                parse = ' '.join(allWords)\n",
    "\n",
    "                for field_name in field_names:\n",
    "                    if str(field_name) in parse:\n",
    "                        num_correct += 1\n",
    "                        if(typeFloat(str(field_name))):\n",
    "                            floatCorrect += 1\n",
    "\n",
    "                        else:\n",
    "                            stringCorrect += 1\n",
    "                            parse.replace(str(field_name),'',1)\n",
    "                    else:\n",
    "                        if(typeFloat(str(field_name))):\n",
    "                            floatWrong += 1\n",
    "                        else:\n",
    "                            stringWrong += 1\n",
    "                    num_total += 1\n",
    "\n",
    "                                # code to check for headers\n",
    "                for heading in headers:\n",
    "                    if str(heading) in parse:\n",
    "                        num_correct += 1\n",
    "                        if (typeFloat(str(heading))):\n",
    "                            floatCorrect += 1\n",
    "\n",
    "                        else: \n",
    "                            stringCorrect += 1\n",
    "                        parse.replace(str(heading), '', 1)\n",
    "\n",
    "                    else: \n",
    "                        if (typeFloat(str(heading))):\n",
    "                            floatWrong += 1\n",
    "                        else:\n",
    "                            stringWrong += 1\n",
    "                    num_total += 1\n",
    "\n",
    "                accuracy = (num_correct / num_total) * 100\n",
    "                time_spent = end_time - start_time\n",
    "                floatAccuracy = (floatCorrect / (floatCorrect+floatWrong)) * 100\n",
    "                stringAccuracy = (stringCorrect / (stringCorrect + stringWrong)) * 100\n",
    "                #print(doc_name)\n",
    "                print(\"Accuracy\", accuracy)\n",
    "                print(\"float Accuracy\", floatAccuracy)\n",
    "                print(\"String Accuracy\", stringAccuracy)\n",
    "                print(\"Time to parse document: {} seconds\".format(time_spent))\n",
    "                print(\"==================================================================\")\n",
    "                accuracy_list.append(accuracy)\n",
    "                time_list.append(time_spent)\n",
    "                float_accuracy_list.append(floatAccuracy)\n",
    "                string_accuracy_list.append(stringAccuracy)\n",
    "\n",
    "                if not FLAGS.no_write_images:\n",
    "                    img_path = os.path.join(FLAGS.output_dir, os.path.basename(im_fn))\n",
    "                    cv2.imwrite(img_path, im[:, :, ::-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-60f6e3f0a357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#if __name__ == '__main__':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#tf.app.run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c6be844dddcd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 633\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "main()\n",
    "#if __name__ == '__main__':\n",
    "    #tf.app.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
